# 第七周作业必做第2题

### 一、表结构

1. 完整订单表

   ```sql
   create table orders
   (
   	order_id bigint not null
   		primary key,
   	amount decimal(11,2) not null,
   	user_id bigint not null,
   	address_id bigint not null,
   	status char not null,
   	create_time varchar(14) not null,
   	update_time varchar(14) not null,
   	constraint idorder_UNIQUE
   		unique (order_id)
   )
   comment '订单表' engine=InnoDB;
   ```

   

2. 简单表

   ```sql
   create table order_test
   (
   	id bigint auto_increment
   		primary key,
   	no bigint not null
   )
   engine=InnoDB;
   ```

### 二、插入测试-定位瓶颈

1. 事务瓶颈：100万条数据，对应100万条insert语句，不开启事务（自动提交），测试结果为：**1159 s**。

   > 代码中不开启事务时，mysql每一条insert语句都会开启、执行、关闭事务，会有大量的事务开关开销。后续的测试中均开启事务。
   >
   > 【结论：批量提交的情景使用事务可以指数级提高效率】

2. 字符串循环拼接瓶颈：100万条数据，对应100万条insert语句，批量提交到orders表，测试结果：**180 s**。

   > 查阅资料得知String+拼接不断创建、回收新对象，效率极低。后续测试中不涉及线程安全问题，均改用StringBuilder。
   >
   > 【结论：瓶颈为String字符串+拼接】

3. 对比数据库表中自增id的影响。

   | 执行时间    | 插入方式                                                     |
   | ----------- | ------------------------------------------------------------ |
   | **7.625 s** | 100万条数据，直接用1条insert语句拼接，提交到order_test表，有自增id |
   | **7.005 s** | 100万条数据，直接用1条insert语句拼接，提交到order_test表，无自增id |

   > 【结论：自增id的影响不大，后续的测试中均使用自增id】

4. 对比分批提交和一次性提交所有的差异。

   | 执行时间     | 插入方式                                       |
   | ------------ | ---------------------------------------------- |
   | **18.293 s** | 100条sql * 1万行记录/条sql，批量提交到orders表 |
   | **18.287 s** | 1条sql * 100万行记录/条sql，提交到orders表     |

   > 【结论：在一定sql数量级范围内，分多条sql批量提交和1条sql提交，效率没有明显差异，可以使用多线程并发的方式来优化】

### 三、多线程插入测试

1. 测试电脑的cpu核心数一共为8个，分别用8个并发线程、16个并发线程来对比测试，16个并发线程能起到少量的优化效果。

   | 数据库表             | 执行时间    | 插入方式                         |
   | -------------------- | ----------- | -------------------------------- |
   | orders（完整）       | **7.648 s** | 8个线程并发，12.5万条记录/个线程 |
   | order_test（简单表） | **3.943 s** | 8个线程并发，12.5万条记录/个线程 |

### 四、1000万条插入测试

1. 分别对比简单表、完整表，8线程、16线程进行插入。

   | 数据库表             | 执行时间      | 插入方式                          |
   | -------------------- | ------------- | --------------------------------- |
   | orders（完整）       | **104.990 s** | 8个线程并发，125万条记录/个线程   |
   | order_test（简单表） | **39.437 s**  | 8个线程并发，125万条记录/个线程   |
   | orders（完整）       | **92.046 s**  | 16个线程并发，62.5万条记录/个线程 |
   | order_test（简单表） | **28.991 s**  | 16个线程并发，62.5万条记录/个线程 |

   > 在实际测试过程中，提高并发线程数，大部分情况下能少量提升性能，但是由于测试过程中cpu、内存的资源使用已接近饱和（90%左右），所以该优化带来的性能提升不是很稳定，线程数增加时部分时候反而耗时更长。

### 五、相关代码

```java
package jdbc.liuzm.homework;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.sql.*;
import java.time.format.DateTimeFormatter;
import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.FutureTask;

/**
 * @Author: liuzm
 * @Date: 2021-09-19 11:06:06
 * @Description: jdbc.liuzm.homework
 * @version: 1.1
 */
public class BatchDatabase {

    HikariConfig hikariConfig = new HikariConfig();
    HikariDataSource hikariDataSource = null;

    public BatchDatabase() {
        hikariConfig.setJdbcUrl("jdbc:mysql://localhost:3306/test");
        hikariConfig.setDriverClassName("com.mysql.cj.jdbc.Driver");
        hikariConfig.setUsername("root");
        hikariConfig.setPassword("123456");
        hikariConfig.setMaximumPoolSize(20);
        hikariDataSource = new HikariDataSource(hikariConfig);
    }


    public Connection getConnFromHikari() throws Exception {
        return hikariDataSource.getConnection();
    }

    public int asyncBatchInsert(CountDownLatch latch) {
        try {
            Connection connection = getConnFromHikari();
            connection.setAutoCommit(false);
            PreparedStatement pstmt = connection.prepareStatement("insert into orders values (?,1000000.00,1000001,9999999,'1',?,?)");
            long beginTime = System.currentTimeMillis();
            DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyyMMddHHmmss");
            LocalDateTime day = LocalDateTime.now();
            String currentDatetime = day.format(formatter);

            //完整订单
            for (int j = 0; j < 10; j++) {
                StringBuilder str_insert = new StringBuilder("insert into orders (amount, user_id, address_id, status, create_time, update_time) values ");
                for (int i = 0; i < 62500 - 1; i++) {
                    str_insert.append("(1000000.00,1000001,9999999,'1',\"" + currentDatetime + "\",\"" + currentDatetime + "\"),");
                }
                str_insert.append("(1000000.00,1000001,9999999,'1',\"" + currentDatetime + "\",\"" + currentDatetime + "\")");
                pstmt.addBatch(str_insert.toString());
            }

//            //简单订单表
//            for (int j = 0; j < 10; j++) {
//                StringBuilder str_insert = new StringBuilder("insert into order_test (no) values ");
//                for (int i = 0; i < 12500 - 1; i++) {
//                    str_insert.append("(" + i + "),");
//                }
//                str_insert.append("(" + 12500 + ")");
//                pstmt.addBatch(str_insert.toString());
//            }
            pstmt.executeBatch();
            connection.commit();
            System.out.println("pstmt.executeBatch()花费时间：" + (System.currentTimeMillis() - beginTime) + " ms");
            pstmt.close();
            connection.close();
            latch.countDown();
        } catch (SQLException se) {
            System.out.println("数据库连接失败");
            se.printStackTrace();
        } catch (Exception e) {
            System.out.println("数据库操作异常");
        }
        return 0;
    }

    public static void main(String[] args) throws Exception {
        BatchDatabase operateDatabase = new BatchDatabase();

        try {
            long beginTime = System.currentTimeMillis();

            /*StringBuilder循环拼接 + 线程池*/
            //每个线程插入125万条，一共需要8个子线程。
            //每个线程插入62.5万条，一共需要16个子线程。
            CountDownLatch latch = new CountDownLatch(8);
            List<CompletableFuture> list = new ArrayList<>(8);
            for (int i = 0; i < 16; i++) {
                CompletableFuture<Void> future = CompletableFuture.runAsync(new FutureTask<>(() -> operateDatabase.asyncBatchInsert(latch)));
                list.add(future);
            }
            latch.await();
            for (CompletableFuture future : list) {
                future.get();
            }

            System.out.println("线程池花费时间：" + (System.currentTimeMillis() - beginTime) + " ms");
        } catch (Exception e) {
            System.out.println("主线程异常");
            e.printStackTrace();
        }
    }
}
```

